@INPROCEEDINGS{surreact,  
	title     = {Synthetic Humans for Action Recognition from Unseen Viewpoints},  
	author    = {Varol, G{\"u}l and Laptev, Ivan and Schmid, Cordelia and Zisserman, Andrew},  
	booktitle = {IJCV},  
	year      = {2021}  
}
@misc{BodyM,
	title={Human Body Measurement Estimation with Adversarial Augmentation}, 
	author={Nataniel Ruiz and Miriam Bellver and Timo Bolkart and Ambuj Arora and Ming C. Lin and Javier Romero and Raja Bala},
	year={2022},
	eprint={2210.05667},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
@misc{pooling,
	title={Pooling Methods in Deep Neural Networks, a Review}, 
	author={Hossein Gholamalinezhad and Hossein Khosravi},
	year={2020},
	eprint={2009.07485},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
@misc{convolutional,
	title={An Introduction to Convolutional Neural Networks}, 
	author={Keiron O'Shea and Ryan Nash},
	year={2015},
	eprint={1511.08458},
	archivePrefix={arXiv},
	primaryClass={cs.NE}
}

@article{smpl,
	author = {Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J.},
	title = {{SMPL}: A Skinned Multi-Person Linear Model},
	journal = {ACM Trans. Graphics (Proc. SIGGRAPH Asia)},
	month = oct,
	number = {6},
	pages = {248:1--248:16},
	publisher = {ACM},
	volume = {34},
	year = {2015}
}
@misc{keras,
	title={Keras},
	author={Chollet, Fran\c{c}ois and others},
	year={2015},
	publisher={GitHub},
	howpublished={\url{https://github.com/keras-team/keras}},
}

@article{opencv,
	author = {Bradski, G.},
	citeulike-article-id = {2236121},
	journal = {Dr. Dobb's Journal of Software Tools},
	keywords = {bibtex-import},
	posted-at = {2008-01-15 19:21:54},
	priority = {4},
	title = {{The OpenCV Library}},
	year = {2000}
}

@article{super,
	author = {Skorvankova, Dana and Riečický, Adam and Madaras, Martin},
	year = {2021},
	month = {12},
	title = {Automatic Estimation of Anthropometric Human Body Measurements}
}  

@article{source,
	title={A Neural Anthropometer Learning from Body Dimensions Computed on Human 3D Meshes},
	author={Yansel Gonzalez Tejeda and Helmut A. Mayer},
	journal={2021 IEEE Symposium Series on Computational Intelligence (SSCI)},
	year={2021},
	pages={1-8},
	url={https://api.semanticscholar.org/CorpusID:238531618}
}

@INPROCEEDINGS{HBDE1,
	author={BenAbdelkader, Chiraz and Yacoob, Yaser},
	booktitle={2008 8th IEEE International Conference on Automatic Face \& Gesture Recognition}, 
	title={Statistical body height estimation from a single image}, 
	year={2008},
	volume={},
	number={},
	pages={1-7},
	keywords={Image segmentation;Layout;Humans;Cameras;Metrology;Geometry;Anthropometry;Forensics;Educational institutions;Bayesian methods},
	doi={10.1109/AFGR.2008.4813453}}


@misc{KeepItSMPL,
	title={Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image}, 
	author={Federica Bogo and Angjoo Kanazawa and Christoph Lassner and Peter Gehler and Javier Romero and Michael J. Black},
	year={2016},
	eprint={1607.08128},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}


@inproceedings{relu,
	title={Rectified linear units improve restricted boltzmann machines},
	author={Nair, Vinod and Hinton, Geoffrey E},
	booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
	pages={807--814},
	year={2010}
}

@Article{numpy,
	title         = {Array programming with {NumPy}},
	author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
	van der Walt and Ralf Gommers and Pauli Virtanen and David
	Cournapeau and Eric Wieser and Julian Taylor and Sebastian
	Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
	and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
	Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
	R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
	G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
	Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
	Travis E. Oliphant},
	year          = {2020},
	month         = sep,
	journal       = {Nature},
	volume        = {585},
	number        = {7825},
	pages         = {357--362},
	doi           = {10.1038/s41586-020-2649-2},
	publisher     = {Springer Science and Business Media {LLC}},
	url           = {https://doi.org/10.1038/s41586-020-2649-2}
}


@article{photogrammetry,
	title={Introduction to photogrammetry},
	author={Schenk, Toni},
	journal={The Ohio State University, Columbus},
	volume={106},
	number={1},
	year={2005}
}

@article{pointcloud,
	title={Learning to Estimate 3D Human Pose From Point Cloud},
	volume={20},
	ISSN={2379-9153},
	url={http://dx.doi.org/10.1109/JSEN.2020.2999849},
	DOI={10.1109/jsen.2020.2999849},
	number={20},
	journal={IEEE Sensors Journal},
	publisher={Institute of Electrical and Electronics Engineers (IEEE)},
	author={Zhou, Yufan and Dong, Haiwei and El Saddik, Abdulmotaleb},
	year={2020},
	month=oct, pages={12334–12342} }

@Article{pointcloudMultiple,
	AUTHOR = {Xu, Tianxu and An, Dong and Jia, Yuetong and Yue, Yang},
	TITLE = {A Review: Point Cloud-Based 3D Human Joints Estimation},
	JOURNAL = {Sensors},
	VOLUME = {21},
	YEAR = {2021},
	NUMBER = {5},
	ARTICLE-NUMBER = {1684},
	URL = {https://www.mdpi.com/1424-8220/21/5/1684},
	PubMedID = {33804411},
	ISSN = {1424-8220},
	ABSTRACT = {Joint estimation of the human body is suitable for many fields such as human–computer interaction, autonomous driving, video analysis and virtual reality. Although many depth-based researches have been classified and generalized in previous review or survey papers, the point cloud-based pose estimation of human body is still difficult due to the disorder and rotation invariance of the point cloud. In this review, we summarize the recent development on the point cloud-based pose estimation of the human body. The existing works are divided into three categories based on their working principles, including template-based method, feature-based method and machine learning-based method. Especially, the significant works are highlighted with a detailed introduction to analyze their characteristics and limitations. The widely used datasets in the field are summarized, and quantitative comparisons are provided for the representative methods. Moreover, this review helps further understand the pertinent applications in many frontier research directions. Finally, we conclude the challenges involved and problems to be solved in future researches.},
	DOI = {10.3390/s21051684}
}

@article{3dScan,
	title = {Exploring the potential of 3D scanning in Industry 4.0: An overview},
	journal = {International Journal of Cognitive Computing in Engineering},
	volume = {3},
	pages = {161-171},
	year = {2022},
	issn = {2666-3074},
	doi = {https://doi.org/10.1016/j.ijcce.2022.08.003},
	url = {https://www.sciencedirect.com/science/article/pii/S2666307422000171},
	author = {Abid Haleem and Mohd Javaid and Ravi Pratap Singh and Shanay Rab and Rajiv Suman and Lalit Kumar and Ibrahim Haleem Khan},
	keywords = {3D scanning, Industry 4.0, Applications, Features, Working process},
	abstract = {A 3D scanner is a non-contact, non-destructive digital device that uses a light line/laser to accurately capture the shape of a physical object into Computer-Aided Design (CAD) data. It generates a point cloud or a set of data points in a coordinate system that accurately depicts a physical object's size and shape. The urge of human beings to build and recreate 3D objects is an essential requirement in the context of Industry 4.0. In Industry 4.0, 3D scanners are helpful for designing, assessing the minor features of any product, capturing freeform, and providing precise point clouds for complicated geometry and curved surfaces. Today advanced technologies are being introduced in industries, and 3D scanning technology is one of the latest emerging technologies. The situation has progressed significantly, and the ever-emerging world of 3D technology still disrupts a variety of sectors. This paper discusses 3D Scanning, its working process, and its adoption for reverse engineering and Industry 4.0 culture. Finally, this paper covers essential features, traits, and applications of 3D Scanning for Industry 4.0. Using different methods, 3D Scanning can collect information about an item, about an object's highness, breadth, and depth. 3D scanners are available on the market from high-end possibilities. They have different resolutions, and now they provide details of the scan to superimpose colour on an object, but the industry wants them to be developed for other quality attributes.}
}

@misc{loss,
	title={Loss Functions and Metrics in Deep Learning}, 
	author={Juan Terven and Diana M. Cordova-Esparza and Alfonso Ramirez-Pedraza and Edgar A. Chavez-Urbiola},
	year={2023},
	eprint={2307.02694},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@article{adolphe,
	title={Adolphe Quetelet and the legacy of the “average man” in psychology.},
	author={Tafreshi, Donna},
	journal={History of Psychology},
	volume={25},
	number={1},
	pages={34},
	year={2022},
	publisher={American Psychological Association}
}

@article{anthrohistory,
	title={12 From a History of Anthropometry to Anthropometric History},
	author={Ulijaszek, Stanley and Komlos, John},
	journal={Human variation: From the laboratory to the field},
	pages={183},
	year={2010},
	publisher={CRC press}
}

@article{domainAdaptation,
	title={A brief review of domain adaptation},
	author={Farahani, Abolfazl and Voghoei, Sahar and Rasheed, Khaled and Arabnia, Hamid R},
	journal={Advances in data science and information engineering: proceedings from ICDATA 2020 and IKE 2020},
	pages={877--894},
	year={2021},
	publisher={Springer}
}

@inproceedings{instanceMethod,
	author = {Huang, Jiayuan and Gretton, Arthur and Borgwardt, Karsten and Sch\"{o}lkopf, Bernhard and Smola, Alex},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {B. Sch\"{o}lkopf and J. Platt and T. Hoffman},
	pages = {},
	publisher = {MIT Press},
	title = {Correcting Sample Selection Bias by Unlabeled Data},
	url = {https://proceedings.neurips.cc/paper_files/paper/2006/file/a2186aa7c086b46ad4e8bf81e2a3a19b-Paper.pdf},
	volume = {19},
	year = {2006}
}

	@inproceedings{featureMethod,
	title={Learning transferable features with deep adaptation networks},
	author={Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael},
	booktitle={International conference on machine learning},
	pages={97--105},
	year={2015},
	organization={PMLR}
}


@InProceedings{featureMethod2,
	title = 	 {Unsupervised Domain Adaptation by Backpropagation},
	author = 	 {Ganin, Yaroslav and Lempitsky, Victor},
	booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
	pages = 	 {1180--1189},
	year = 	 {2015},
	editor = 	 {Bach, Francis and Blei, David},
	volume = 	 {37},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Lille, France},
	month = 	 {07--09 Jul},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v37/ganin15.pdf},
	url = 	 {https://proceedings.mlr.press/v37/ganin15.html},
	abstract = 	 {Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of "deep" features that are (i) discriminative for the main learning task on the source domain and (ii) invariant with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a simple new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation. Overall, the approach can be implemented with little effort using any of the deep-learning packages. The method performs very well in a series of image classification experiments, achieving adaptation effect in the presence of big domain shifts and outperforming previous state-of-the-art on Office datasets.}
}

@article{parameterMethod,
	title={Deep domain confusion: Maximizing for domain invariance},
	author={Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
	journal={arXiv preprint arXiv:1412.3474},
	year={2014}
}

@inproceedings{hybridMethod,
	title={Cycada: Cycle-consistent adversarial domain adaptation},
	author={Hoffman, Judy and Tzeng, Eric and Park, Taesung and Zhu, Jun-Yan and Isola, Phillip and Saenko, Kate and Efros, Alexei and Darrell, Trevor},
	booktitle={International conference on machine learning},
	pages={1989--1998},
	year={2018},
	organization={Pmlr}
}

@article{synthDataRobust,
	author       = {Jonathan Tremblay and
	Aayush Prakash and
	David Acuna and
	Mark Brophy and
	Varun Jampani and
	Cem Anil and
	Thang To and
	Eric Cameracci and
	Shaad Boochoon and
	Stan Birchfield},
	title        = {Training Deep Networks with Synthetic Data: Bridging the Reality Gap
	by Domain Randomization},
	journal      = {CoRR},
	volume       = {abs/1804.06516},
	year         = {2018},
	url          = {http://arxiv.org/abs/1804.06516},
	eprinttype    = {arXiv},
	eprint       = {1804.06516},
	timestamp    = {Mon, 13 Aug 2018 16:48:18 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1804-06516.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{synthDataReview,
	title={Machine Learning for Synthetic Data Generation: A Review}, 
	author={Yingzhou Lu and Minjie Shen and Huazheng Wang and Xiao Wang and Capucine van Rechem and Tianfan Fu and Wenqi Wei},
	year={2024},
	eprint={2302.04062},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{CycleGAN,
	title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks}, 
	author={Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
	year={2020},
	eprint={1703.10593},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}





